{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9aa64949-a412-4bb8-8fd5-2dfe74edad03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import random\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de1a4104-2c4c-45e2-8016-b912367c38a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 10-K/10-K-A filings found: 73799\n"
     ]
    }
   ],
   "source": [
    "# 1. Paths and file discovery (handles 10k_unzipped + 2021–2024)\n",
    "\n",
    "# Base directory where the bucket is mounted\n",
    "BASE_DIR = Path(\"/home/jupyter/data\")\n",
    "\n",
    "# Legacy layout: 2016–2020 inside 10k_unzipped\n",
    "LEGACY_ROOT = BASE_DIR / \"10k_unzipped\"\n",
    "LEGACY_YEARS = [str(y) for y in range(2016, 2021)]  # '2016'...'2020'\n",
    "\n",
    "# New layout: 2021–2024 at the top level\n",
    "NEW_YEARS = [\"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "\n",
    "# def collect_all_files():\n",
    "#     all_files = []\n",
    "\n",
    "#     # 2016–2020\n",
    "#     for year in LEGACY_YEARS:\n",
    "#         year_dir = LEGACY_ROOT / year\n",
    "#         if not year_dir.is_dir():\n",
    "#             continue\n",
    "#         for path in year_dir.rglob(\"*.txt\"):\n",
    "#             all_files.append(path)\n",
    "\n",
    "#     # 2021–2024\n",
    "#     for year in NEW_YEARS:\n",
    "#         year_dir = BASE_DIR / year\n",
    "#         if not year_dir.is_dir():\n",
    "#             continue\n",
    "#         for path in year_dir.rglob(\"*.txt\"):\n",
    "#             all_files.append(path)\n",
    "\n",
    "#     all_files = sorted(all_files)\n",
    "#     print(f\"Total txt filings found: {len(all_files)}\")\n",
    "#     return all_files\n",
    "\n",
    "def is_10k(path):\n",
    "    \"\"\"\n",
    "    Returns True if the file is likely a 10-K or 10-K/A based on filename.\n",
    "    Adjust the logic if your filenames don't contain the form type.\n",
    "    \"\"\"\n",
    "    # Convert filename to uppercase for case-insensitive check\n",
    "    name = path.name.upper()\n",
    "    \n",
    "    # Common patterns: \"10-K\", \"10-K-A\", \"10-K_...\", etc.\n",
    "    # Exclude \"10-Q\" explicitly or just look for \"10-K\"\n",
    "    if \"10-K\" in name:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def collect_all_files():\n",
    "    all_files = []\n",
    "\n",
    "    # 2016–2020\n",
    "    for year in LEGACY_YEARS:\n",
    "        year_dir = LEGACY_ROOT / year\n",
    "        if not year_dir.is_dir():\n",
    "            continue\n",
    "        # Iterate over all txt files, but only append if they pass the check\n",
    "        for path in year_dir.rglob(\"*.txt\"):\n",
    "            if is_10k(path):\n",
    "                all_files.append(path)\n",
    "\n",
    "    # 2021–2024\n",
    "    for year in NEW_YEARS:\n",
    "        year_dir = BASE_DIR / year\n",
    "        if not year_dir.is_dir():\n",
    "            continue\n",
    "        for path in year_dir.rglob(\"*.txt\"):\n",
    "            if is_10k(path):\n",
    "                all_files.append(path)\n",
    "\n",
    "    all_files = sorted(all_files)\n",
    "    print(f\"Total 10-K/10-K-A filings found: {len(all_files)}\")\n",
    "    return all_files\n",
    "\n",
    "all_files = collect_all_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ee340-5b5a-4c11-a465-23b1f6b08ddb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1A. NLP Workflow building (FinBert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7411b233-fbbb-4d84-8593-a2d3282a8d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Helper: parse basic metadata from filename\n",
    "\n",
    "FILENAME_REGEX = re.compile(\n",
    "    r\"(?P<date>\\d{8})_(?P<form>[0-9A-Z\\-]+)_edgar_data_(?P<cik>\\d+)_\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_filename_meta(path: Path):\n",
    "    \"\"\"\n",
    "    Best-effort parse of date, form, cik from the filename.\n",
    "    Returns dict with keys: cik, form, filing_date (YYYY-MM-DD), year.\n",
    "    \"\"\"\n",
    "    name = path.name\n",
    "    m = FILENAME_REGEX.search(name)\n",
    "    if not m:\n",
    "        return {\"cik\": None, \"form\": None, \"filing_date\": None, \"year\": None}\n",
    "\n",
    "    raw_date = m.group(\"date\")\n",
    "    filing_date = f\"{raw_date[0:4]}-{raw_date[4:6]}-{raw_date[6:8]}\"\n",
    "    year = int(raw_date[0:4])\n",
    "\n",
    "    return {\n",
    "        \"cik\": m.group(\"cik\"),\n",
    "        \"form\": m.group(\"form\"),\n",
    "        \"filing_date\": filing_date,\n",
    "        \"year\": year,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9b018a-9e7e-4f60-8591-1b218016038e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Extract Item 1A – Risk Factors from text\n",
    "\n",
    "ITEM_1A_REGEX = re.compile(\n",
    "    r\"ITEM\\s+1A\\.\\s*RISK\\s+FACTORS(.*?)(?=ITEM\\s+1B\\.)\",\n",
    "    re.IGNORECASE | re.DOTALL\n",
    ")\n",
    "\n",
    "def extract_item_1a(full_text: str):\n",
    "    \"\"\"\n",
    "    Extract 'Item 1A. Risk Factors' section from a 10-K (or 10-Q).\n",
    "    Returns the section text or None if not found.\n",
    "    \"\"\"\n",
    "    m = ITEM_1A_REGEX.search(full_text)\n",
    "    if not m:\n",
    "        return None\n",
    "    section = m.group(1)\n",
    "    # Light cleanup\n",
    "    section = section.strip()\n",
    "    return section if section else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839c6b30-d575-4f35-b77b-8ed46074ea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 4. FinBert sentiment scoring function\n",
    "\n",
    "# Load FinBERT model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "finbert_model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finbert_model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "LABELS = [\"positive\", \"neutral\", \"negative\"]  # FinBERT ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9da1998-fb0c-4907-8c0d-bf2bf29d0396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.1 Scoring function \n",
    "\n",
    "def finbert_score(text: str, max_tokens=400, chunk_tokens=350):\n",
    "    \"\"\"\n",
    "    Score text with FinBERT.\n",
    "    - If very long, split into word chunks, score each, and average probabilities.\n",
    "    Returns dict with positive/neutral/negative and dominant_label.\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return {\n",
    "            \"fb_pos\": None,\n",
    "            \"fb_neu\": None,\n",
    "            \"fb_neg\": None,\n",
    "            \"fb_label\": None,\n",
    "        }\n",
    "\n",
    "    # crude word-based chunking to control length\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_tokens):\n",
    "        chunk = \" \".join(words[i:i + chunk_tokens])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    probs_accum = torch.zeros(len(LABELS), device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for chunk in chunks:\n",
    "            inputs = tokenizer(\n",
    "                chunk,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=max_tokens,\n",
    "                padding=\"max_length\"\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits.mean(dim=0)  # average over sequence\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            probs_accum += probs\n",
    "\n",
    "    probs_mean = probs_accum / len(chunks)\n",
    "    probs_mean = probs_mean.cpu().tolist()\n",
    "\n",
    "    fb_pos, fb_neu, fb_neg = probs_mean\n",
    "    idx = int(torch.tensor(probs_mean).argmax())\n",
    "    fb_label = LABELS[idx]\n",
    "\n",
    "    return {\n",
    "        \"fb_pos\": fb_pos,\n",
    "        \"fb_neu\": fb_neu,\n",
    "        \"fb_neg\": fb_neg,\n",
    "        \"fb_label\": fb_label,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82239a20-9378-4af5-b3a8-5cffef8d926f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1B. NLP Workflow building (ClimateBert - Transition / Physical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4c121e-f1b2-4408-841b-75e7693da3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define climate-risk keyword dictionaries\n",
    "\n",
    "# 1. Physical risk keywords (you can extend this list)\n",
    "PHYSICAL_TERMS = [\n",
    "    \"flood\", \"flooding\", \"inundation\", \"storm surge\",\n",
    "    \"hurricane\", \"cyclone\", \"typhoon\", \"tornado\",\n",
    "    \"wildfire\", \"forest fire\", \"bushfire\",\n",
    "    \"drought\", \"water stress\", \"water scarcity\",\n",
    "    \"extreme heat\", \"heatwave\", \"heat wave\",\n",
    "    \"extreme temperature\", \"cold spell\",\n",
    "    \"storm\", \"severe storm\", \"hailstorm\",\n",
    "    \"sea level rise\", \"coastal erosion\",\n",
    "]\n",
    "\n",
    "# Transition + general climate terms (you can also use these later)\n",
    "TRANSITION_TERMS = [\n",
    "    \"climate change\", \"global warming\", \"greenhouse gas\", \"ghg\",\n",
    "    \"emissions\", \"carbon price\", \"carbon tax\", \"carbon credit\",\n",
    "    \"net zero\", \"decarbonisation\", \"decarbonization\",\n",
    "    \"energy transition\", \"low-carbon\", \"renewable energy\",\n",
    "    \"stranded asset\", \"climate regulation\", \"paris agreement\",\n",
    "]\n",
    "\n",
    "# 2. Define simple sentence splitter + climate-passage extractor\n",
    "\n",
    "def split_into_sentences(text: str):\n",
    "    if not text:\n",
    "        return []\n",
    "    # very simple splitter: split on . ! ? followed by whitespace\n",
    "    parts = re.split(r'(?<=[\\.\\!\\?])\\s+', text)\n",
    "    # strip and keep non-empty\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "\n",
    "def is_climate_sentence(sentence: str):\n",
    "    s = sentence.lower()\n",
    "    return any(kw in s for kw in PHYSICAL_TERMS + TRANSITION_TERMS)\n",
    "\n",
    "\n",
    "def extract_climate_passages(text: str, min_sentences: int = 1):\n",
    "    \"\"\"\n",
    "    Returns (climate_text, n_climate_sentences, n_total_sentences)\n",
    "    \"\"\"\n",
    "    sentences = split_into_sentences(text)\n",
    "    if not sentences:\n",
    "        return \"\", 0, 0\n",
    "\n",
    "    climate_sentences = [s for s in sentences if is_climate_sentence(s)]\n",
    "    climate_text = \" \".join(climate_sentences)\n",
    "\n",
    "    if len(climate_sentences) < min_sentences:\n",
    "        # Consider it as 'no climate content'\n",
    "        return \"\", len(climate_sentences), len(sentences)\n",
    "\n",
    "    return climate_text, len(climate_sentences), len(sentences)\n",
    "\n",
    "# 3. Keyword-based intensity scores\n",
    "\n",
    "def keyword_hits(text: str, keywords):\n",
    "    if not text:\n",
    "        return 0\n",
    "    t = text.lower()\n",
    "    return sum(t.count(k.lower()) for k in keywords)\n",
    "\n",
    "\n",
    "def keyword_intensity(text: str, keywords):\n",
    "    \"\"\"\n",
    "    Raw hits and length-normalised hits (per 1,000 characters).\n",
    "    \"\"\"\n",
    "    hits = keyword_hits(text, keywords)\n",
    "    length = max(len(text), 1)\n",
    "    norm = hits * 1000.0 / length\n",
    "    return hits, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6290ce9-256b-4d06-82a3-3617e10bc4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device index: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 4. Load the climate-specific model: ClimateBERT risk (using pipeline for the test)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Using device index:\", device)\n",
    "\n",
    "climate_tp_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/transition-physical\",\n",
    "    tokenizer=\"climatebert/distilroberta-base-climate-detector\",\n",
    "    device=device,\n",
    "    return_all_scores=True,   # important: we want all 3 probs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81c77970-6818-4863-8fc0-d39941278b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Helper to score a text with transition/physical probs\n",
    "\n",
    "def transition_physical_scores(text: str, max_length: int = 256):\n",
    "    \"\"\"\n",
    "    Run climatebert/transition-physical on a text and return:\n",
    "        p_transition, p_none, p_physical\n",
    "\n",
    "    If text is empty → returns (None, None, None).\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return None, None, None\n",
    "\n",
    "    # pipeline returns: [[{\"label\": \"LABEL_0\", \"score\": ...}, {...}, {...}]]\n",
    "    outputs = climate_tp_pipe(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )[0]\n",
    "\n",
    "    scores_by_label = {d[\"label\"]: d[\"score\"] for d in outputs}\n",
    "\n",
    "    p_transition = scores_by_label.get(\"LABEL_0\", 0.0)\n",
    "    p_none       = scores_by_label.get(\"LABEL_1\", 0.0)\n",
    "    p_physical   = scores_by_label.get(\"LABEL_2\", 0.0)\n",
    "\n",
    "    return p_transition, p_none, p_physical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72d23e-bcb7-4c78-8441-12eeae997a51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1C. NLP Workflow building (ClimateBert: Climate Detector → Transition-Physical → Climate Specificity)\n",
    "Step 1 — Extract Item 1A → split into sentences\n",
    "\n",
    "Step 2 — Use keyword filter to find candidate climate sentences (very fast)\n",
    "\n",
    "Step 3 — Pass only those sentences to Climate Detector\n",
    "\n",
    "Step 4 — Pass filtered sentences to transition-physical\n",
    "\n",
    "Step 5 — Compute specificity score\n",
    "\n",
    "Step 6 — Aggregate to firm-year metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e8973a-6dd8-46a1-9957-3552314fa435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Parse CIK, form, filing date, year from file name\n",
    "\n",
    "def parse_filename_meta(path: Path):\n",
    "    fname = path.name\n",
    "    m = re.match(\n",
    "        r'(?P<date>\\d{8})_(?P<form>[0-9A-Z\\-]+)_edgar_data_(?P<cik>\\d+)_',\n",
    "        fname\n",
    "    )\n",
    "    if not m:\n",
    "        return {\"cik\": None, \"form\": None, \"filing_date\": None, \"year\": None}\n",
    "    \n",
    "    date_str = m.group(\"date\")  # YYYYMMDD\n",
    "    filing_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "    return {\n",
    "        \"cik\": m.group(\"cik\"),\n",
    "        \"form\": m.group(\"form\"),\n",
    "        \"filing_date\": filing_date,\n",
    "        \"year\": int(date_str[:4]),\n",
    "    }\n",
    "\n",
    "# 2. Extract Item 1A (Risk Factors)\n",
    "\n",
    "def extract_item_1a(text: str):\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # normalize spaces + case for matching\n",
    "    pattern = re.compile(\n",
    "        r'ITEM\\s+1A\\.(.*?)(ITEM\\s+1B\\.|ITEM\\s+2\\.)',\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    m = pattern.search(text)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "# 3. Sentence splitting + climate keyword filter\n",
    "\n",
    "PHYSICAL_TERMS = [\n",
    "    # Floods & storms\n",
    "    \"flood\", \"flooding\", \"flash flood\", \"storm surge\",\n",
    "    \"coastal flood\", \"inland flood\", \"river flood\",\n",
    "    \"hurricane\", \"cyclone\", \"typhoon\", \"tornado\",\n",
    "    \"severe storm\", \"winter storm\", \"ice storm\",\n",
    "    \"hailstorm\", \"windstorm\", \"extreme wind\", \"gale force\",\n",
    "\n",
    "    # Wildfires\n",
    "    \"wildfire\", \"wild fire\", \"forest fire\", \"bushfire\",\n",
    "    \"fire season\", \"smoke exposure\", \"wildfire risk\",\n",
    "\n",
    "    # Heat-related risks\n",
    "    \"extreme heat\", \"heatwave\", \"heat wave\",\n",
    "    \"high temperature\", \"record heat\", \"temperature anomaly\",\n",
    "    \"thermal stress\", \"heat stress\",\n",
    "\n",
    "    # Drought & water stress\n",
    "    \"drought\", \"extreme drought\", \"water stress\",\n",
    "    \"water scarcity\", \"water shortage\", \"water depletion\",\n",
    "    \"reduced rainfall\", \"precipitation deficit\",\n",
    "\n",
    "    # Sea-level rise & coastal risks\n",
    "    \"sea level rise\", \"coastal erosion\", \"coastal retreat\",\n",
    "    \"coastal inundation\", \"tidal flooding\", \"saltwater intrusion\",\n",
    "\n",
    "    # Cold extremes\n",
    "    \"cold spell\", \"extreme cold\", \"polar vortex\",\n",
    "    \"winter freeze\", \"deep freeze\", \"freezing event\",\n",
    "\n",
    "    # Chronic climate trends\n",
    "    \"changing rainfall\", \"changing precipitation\",\n",
    "    \"temperature increase\", \"warming trend\",\n",
    "    \"long-term climate trend\", \"long-term heat\",\n",
    "\n",
    "    # Secondary physical risks (financial-relevant)\n",
    "    \"infrastructure damage\", \"property damage\",\n",
    "    \"facility damage\", \"operational disruption\",\n",
    "    \"supply chain disruption\", \"business interruption\",\n",
    "    \"power outage\", \"grid failure\", \"water availability\",\n",
    "    \"crop failure\", \"agricultural loss\",\n",
    "\n",
    "    # FEMA / EM-DAT wording that appears in filings\n",
    "    \"natural disaster\", \"natural hazard\", \"catastrophic event\",\n",
    "    \"extreme weather\", \"adverse weather\",\n",
    "    \"weather-related disruption\", \"weather event\",\n",
    "\n",
    "    # Insurance / actuarial language\n",
    "    \"insured loss\", \"catastrophe risk\", \"catastrophic loss\",\n",
    "]\n",
    "\n",
    "TRANSITION_TERMS = [\n",
    "    # General climate transition\n",
    "    \"climate change\", \"global warming\",\n",
    "    \"climate-related\", \"climate risk\",\n",
    "\n",
    "    # Emissions & carbon language\n",
    "    \"greenhouse gas\", \"ghg\", \"co2\", \"carbon dioxide\",\n",
    "    \"carbon emissions\", \"emissions reduction\",\n",
    "    \"emissions target\", \"emissions cap\",\n",
    "\n",
    "    # Carbon pricing & markets\n",
    "    \"carbon price\", \"carbon tax\", \"carbon levy\",\n",
    "    \"carbon fee\", \"cap-and-trade\", \"cap and trade\",\n",
    "    \"carbon credit\", \"carbon offset\", \"carbon trading\",\n",
    "    \"emissions trading scheme\", \"ets\",\n",
    "\n",
    "    # Climate policy\n",
    "    \"climate regulation\", \"climate disclosure rule\",\n",
    "    \"environmental regulation\", \"energy regulation\",\n",
    "    \"climate legislation\", \"regulatory requirement\",\n",
    "    \"regulatory risk\",\n",
    "\n",
    "    # Net-zero policies\n",
    "    \"net zero\", \"net-zero\", \"zero-carbon\",\n",
    "    \"carbon-neutral\", \"carbon neutrality\",\n",
    "    \"decarbonisation\", \"decarbonization\",\n",
    "\n",
    "    # Energy transition\n",
    "    \"energy transition\", \"energy efficiency\",\n",
    "    \"low-carbon\", \"low carbon\",\n",
    "    \"renewable energy\", \"clean energy\",\n",
    "    \"solar\", \"wind power\", \"hydropower\",\n",
    "\n",
    "    # Stranded assets & financial risks\n",
    "    \"stranded asset\", \"asset stranding\",\n",
    "    \"transition cost\", \"transition risk\",\n",
    "    \"compliance cost\", \"carbon cost\",\n",
    "\n",
    "    # Climate governance / reporting\n",
    "    \"tcfd\", \"task force on climate-related financial disclosures\",\n",
    "    \"esg reporting\", \"climate reporting\", \"sustainability report\",\n",
    "\n",
    "    # Litigation\n",
    "    \"climate litigation\", \"environmental litigation\",\n",
    "\n",
    "    # Reputation & market\n",
    "    \"climate reputation\", \"climate perception\",\n",
    "    \"sustainability expectations\", \"investor pressure\",\n",
    "\n",
    "    # Paris agreement\n",
    "    \"paris agreement\", \"paris-aligned\",\n",
    "]\n",
    "\n",
    "# Split into sentences as ML models work better on coherent chunks\n",
    "def split_into_sentences(text: str):\n",
    "    if not text:\n",
    "        return []\n",
    "    parts = re.split(r'(?<=[\\.\\!\\?])\\s+', text)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "# Climate keyword detection (from the lists)\n",
    "def is_climate_sentence(s: str):\n",
    "    s_low = s.lower()\n",
    "    return any(kw in s_low for kw in PHYSICAL_TERMS + TRANSITION_TERMS)\n",
    "\n",
    "def extract_climate_passages(text: str, min_sentences: int = 1):\n",
    "    sents = split_into_sentences(text)\n",
    "    if not sents:\n",
    "        return \"\", 0, 0\n",
    "    climate_sents = [s for s in sents if is_climate_sentence(s)]\n",
    "    climate_text = \" \".join(climate_sents)\n",
    "    if len(climate_sents) < min_sentences:\n",
    "        return \"\", len(climate_sents), len(sents)\n",
    "    return climate_text, len(climate_sents), len(sents)\n",
    "\n",
    "def keyword_hits(text: str, keywords):\n",
    "    if not text:\n",
    "        return 0\n",
    "    t = text.lower()\n",
    "    return sum(t.count(k.lower()) for k in keywords)\n",
    "\n",
    "def keyword_intensity(text: str, keywords):\n",
    "    hits = keyword_hits(text, keywords)\n",
    "    length = max(len(text), 1)\n",
    "    norm = hits * 1000.0 / length   # hits per 1000 chars\n",
    "    return hits, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "453753e0-6a33-4da9-a7b2-dd562d128276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device index: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 4. Load ClimateBERT models with pipeline\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Using device index:\", device)\n",
    "\n",
    "# Climate detector -> returns if the text is climate-related or not climate-related\n",
    "detector_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/distilroberta-base-climate-detector\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Transition-physical -> tells if a passage discusses transition / physical risks (or neither)\n",
    "tp_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/transition-physical\",\n",
    "    tokenizer=\"climatebert/distilroberta-base-climate-detector\",\n",
    "    device=device,\n",
    "    return_all_scores=True,   # important: we want all 3 probs\n",
    ")\n",
    "\n",
    "# Climate-specificity -> predict whether text is specific (quantified risk, named scenario, named hazard) vs general (vague, boilerplate)\n",
    "spec_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/distilroberta-base-climate-specificity\",\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520fbae0-d088-4c21-9ca3-8d640a4421e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Helpers to turn outputs into probabilities (auto-adapt if labels are 2-way or 3-way)\n",
    "\n",
    "def scores_from_pipeline(pipe, text: str, max_length: int = 256):\n",
    "    \"\"\"\n",
    "    Generic helper: returns {label: score} for a text.\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return {}\n",
    "    outputs = pipe(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )[0]  # first (and only) sample\n",
    "    return {d[\"label\"]: d[\"score\"] for d in outputs}\n",
    "\n",
    "def detector_scores(text: str):\n",
    "    d = scores_from_pipeline(detector_pipe, text)\n",
    "    # climate-detector: LABEL_0 = not climate, LABEL_1 = climate\n",
    "    p_climate = d.get(\"LABEL_1\", None)\n",
    "    p_non = d.get(\"LABEL_0\", None)\n",
    "    return p_climate, p_non\n",
    "\n",
    "def transition_physical_scores(text: str):\n",
    "    d = scores_from_pipeline(tp_pipe, text)\n",
    "    # model might be 2-label or 3-label; handle both\n",
    "    if \"LABEL_2\" in d:\n",
    "        p_trans = d.get(\"LABEL_0\", None)\n",
    "        p_none  = d.get(\"LABEL_1\", None)\n",
    "        p_phys  = d.get(\"LABEL_2\", None)\n",
    "    else:\n",
    "        # 2-label variant: LABEL_0 = Transition, LABEL_1 = Physical\n",
    "        p_trans = d.get(\"LABEL_0\", None)\n",
    "        p_phys  = d.get(\"LABEL_1\", None)\n",
    "        p_none  = None\n",
    "    return p_trans, p_phys, p_none\n",
    "\n",
    "def specificity_scores(text: str):\n",
    "    d = scores_from_pipeline(spec_pipe, text)\n",
    "    # LABEL_0 = low, LABEL_1 = medium, LABEL_2 = high specificity\n",
    "    p_low  = d.get(\"LABEL_0\", None)\n",
    "    p_med  = d.get(\"LABEL_1\", None)\n",
    "    p_high = d.get(\"LABEL_2\", None)\n",
    "    return p_low, p_med, p_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f0cd4-16c9-4f3a-b6db-b8c4ca3c5e26",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1D. NLP Workflow building (ClimateBert: Climate Detector → Transition-Physical → Climate Specificit) - no keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cf1a091-df23-421c-a755-2e39f89d162f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device index: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1) ClimateBERT pipelines\n",
    "# --------------------------\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Using device index:\", device)\n",
    "\n",
    "# Climate detector -> returns if the text is climate-related or not climate-related\n",
    "detector_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/distilroberta-base-climate-detector\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Transition-physical -> tells if a passage discusses transition / physical risks (or neither)\n",
    "tp_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/transition-physical\",\n",
    "    tokenizer=\"climatebert/distilroberta-base-climate-detector\",\n",
    "    device=device,\n",
    "    return_all_scores=True,   # important: we want all 3 probs\n",
    ")\n",
    "\n",
    "# map labels outputs from tp_pipe for clarity (based on a test)\n",
    "label_map = {\n",
    "    \"LABEL_0\": \"transition\", \n",
    "    \"LABEL_1\": \"none\",       \n",
    "    \"LABEL_2\": \"physical\"\n",
    "}\n",
    "\n",
    "# Climate-specificity -> predict whether text is specific (quantified risk, named scenario, named hazard) vs general (vague, boilerplate)\n",
    "spec_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"climatebert/distilroberta-base-climate-specificity\",\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c02578d8-8f09-42f7-b828-d7a6497b7719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2) Utility: parse filename\n",
    "# --------------------------\n",
    "\n",
    "def parse_filename_meta(path: Path):\n",
    "    fname = path.name\n",
    "    m = re.match(\n",
    "        r'(?P<date>\\d{8})_(?P<form>[0-9A-Z\\-]+)_edgar_data_(?P<cik>\\d+)_',\n",
    "        fname\n",
    "    )\n",
    "    if not m:\n",
    "        return {\"cik\": None, \"form\": None, \"filing_date\": None, \"year\": None}\n",
    "    date_str = m.group(\"date\")\n",
    "    filing_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "    return {\n",
    "        \"cik\": m.group(\"cik\"),\n",
    "        \"form\": m.group(\"form\"),\n",
    "        \"filing_date\": filing_date,\n",
    "        \"year\": int(date_str[:4]),\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# 3) Extract full Item 1A\n",
    "# --------------------------\n",
    "\n",
    "# def extract_item_1a(text: str):\n",
    "#     pattern = re.compile(\n",
    "#         r'ITEM\\s+1A\\.?(.*?)(ITEM\\s+1B\\.|ITEM\\s+2\\.)',\n",
    "#         flags=re.IGNORECASE | re.DOTALL\n",
    "#     )\n",
    "#     m = pattern.search(text)\n",
    "#     return m.group(1) if m else None\n",
    "\n",
    "def extract_item_1a(text: str):\n",
    "    \"\"\"\n",
    "    Robust extraction of Item 1A (Risk Factors).\n",
    "    Strategies used:\n",
    "    1. Case-insensitive search.\n",
    "    2. Mandatory 'Risk Factors' title to avoid TOC matches.\n",
    "    3. Finding ALL matches and returning the longest one (to bypass TOC entries).\n",
    "    \"\"\"\n",
    "    \n",
    "    # IMPROVEMENT 1: Look for \"Item 1A\" followed optionally by punctuation, \n",
    "    # then explicitly \"Risk Factors\". This filters out many TOC entries.\n",
    "    # We use [\\.\\:\\-\\s]* to allow for separators like \"Item 1A: Risk Factors\" or \"Item 1A. Risk Factors\"\n",
    "    # We use (?i) for case insensitivity inside the pattern.\n",
    "    start_pattern = r'ITEM\\s+1A[\\.\\:\\-\\s]*Risk\\s+Factors'\n",
    "    \n",
    "    # IMPROVEMENT 2: The end pattern looks for the next likely headers (1B or 2).\n",
    "    # We include word boundaries (\\b) to avoid matching \"Item 20\" as \"Item 2\".\n",
    "    end_pattern = r'(ITEM\\s+1B|ITEM\\s+2)\\b'\n",
    "    \n",
    "    # Combine into a single regex.\n",
    "    # Note: We use DOTALL (re.S) so the dot (.) matches newlines.\n",
    "    regex = re.compile(\n",
    "        f\"({start_pattern})(.*?)({end_pattern})\", \n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    \n",
    "    matches = regex.findall(text)\n",
    "    \n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    # IMPROVEMENT 3: The \"Longest Match\" Heuristic.\n",
    "    # A TOC entry is usually short (< 500 chars). The real section is long.\n",
    "    # matches is a list of tuples: [(start_match, content, end_match), ...]\n",
    "    # We want the 'content' group (index 1).\n",
    "    candidates = [m[1] for m in matches]\n",
    "    \n",
    "    # Sort by length, descending, and take the longest.\n",
    "    best_candidate = max(candidates, key=len)\n",
    "    \n",
    "    # Optional: Logic to reject if even the best candidate is too short to be real\n",
    "    if len(best_candidate) < 1000:\n",
    "        return None\n",
    "\n",
    "    return best_candidate.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ddf6dcd-4dde-4c83-a388-5cf3bff020f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_TEST = 10  \n",
    "\n",
    "if len(all_files) <= N_TEST:\n",
    "    sample_files = all_files\n",
    "else:\n",
    "    sample_files = random.sample(all_files, N_TEST)\n",
    "\n",
    "len(sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a394afa1-6aba-451d-9f69-f765bfcb81f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cff1c87b514993b0a93f662618619a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing ClimateBERT (full 1A):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 4) Process small subsample\n",
    "# --------------------------\n",
    "\n",
    "# Configuration for sliding window\n",
    "# 512 is the hard limit for BERT-based models. \n",
    "# We use slightly less (500) to leave room for special tokens [CLS], [SEP] added by the pipeline.\n",
    "CHUNK_SIZE = 500  \n",
    "STRIDE = 100       # Overlap between chunks to ensure context isn't lost at the edges\n",
    "\n",
    "def get_sliding_windows(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes text and slices it into overlapping windows.\n",
    "    Returns a list of decoded string chunks safe for the model.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize the entire document at once (no truncation yet)\n",
    "    encodings = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"][0]\n",
    "    \n",
    "    # 2. If text is short, return it as a single chunk\n",
    "    if len(input_ids) <= CHUNK_SIZE:\n",
    "        return [text]\n",
    "    \n",
    "    # 3. Create windows\n",
    "    windows = []\n",
    "    total_tokens = len(input_ids)\n",
    "    \n",
    "    for i in range(0, total_tokens, CHUNK_SIZE - STRIDE):\n",
    "        # Define the window\n",
    "        chunk_ids = input_ids[i : i + CHUNK_SIZE]\n",
    "        \n",
    "        # Decode back to string so the pipeline can consume it naturally\n",
    "        # skip_special_tokens=True ensures we don't end up with weird [UNK] artifacts\n",
    "        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        windows.append(chunk_text)\n",
    "        \n",
    "        # Stop if we've reached the end\n",
    "        if i + CHUNK_SIZE >= total_tokens:\n",
    "            break\n",
    "            \n",
    "    return windows\n",
    "\n",
    "# --------------------------\n",
    "# 4) Process with Sliding Window\n",
    "# --------------------------\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Access the tokenizer from one of your pipes (assuming they share similar base arch like DistilRoBERTa)\n",
    "# If they are different architectures, use the specific tokenizer for each pipe.\n",
    "main_tokenizer = detector_pipe.tokenizer \n",
    "\n",
    "for path in tqdm(sample_files, desc=\"Testing ClimateBERT (full 1A)\"):\n",
    "    meta = parse_filename_meta(path)\n",
    "    try:\n",
    "        text = path.read_text(errors=\"ignore\")\n",
    "        item_1a = extract_item_1a(text)\n",
    "        \n",
    "        # Skip empty files immediately\n",
    "        if not item_1a:\n",
    "            rows.append({**meta, \"item_1a_len\": 0, \"p_det\": None, \"p_phys\": None, \"p_trans\": None, \"p_spec_high\": None})\n",
    "            continue\n",
    "\n",
    "        # --- STEP 1: CHUNK THE TEXT ---\n",
    "        # Instead of item_1a[:4500], we get a list of valid token-safe strings\n",
    "        chunks = get_sliding_windows(item_1a, main_tokenizer)\n",
    "\n",
    "        # Storage for scores across all chunks in this document\n",
    "        doc_scores = {\n",
    "            \"p_det\": [],\n",
    "            \"p_phys\": [],\n",
    "            \"p_trans\": [],\n",
    "            \"p_spec_high\": []\n",
    "        }\n",
    "\n",
    "        # --- STEP 2: BATCH INFERENCE ---\n",
    "        # Passing the list 'chunks' directly to pipe() allows it to batch process if on GPU\n",
    "        # We process all chunks for the document at once.\n",
    "        \n",
    "        # 1. Detector\n",
    "        det_results = detector_pipe(chunks)\n",
    "        for res in det_results:\n",
    "            # Handle potential list wrapper if pipe returns list of lists\n",
    "            r = res if isinstance(res, dict) else res[0] \n",
    "            label = r[\"label\"].lower()\n",
    "            score = r[\"score\"]\n",
    "            \n",
    "            # Map label to probability\n",
    "            # If label is 'climate-related', prob is score. If 'not', prob is 1-score (or just ignore if using max)\n",
    "            if label in [\"climate_related\", \"climate-related\", \"climate\"]:\n",
    "                doc_scores[\"p_det\"].append(score)\n",
    "            else:\n",
    "                doc_scores[\"p_det\"].append(1 - score) # Invert score if it's \"not climate\"\n",
    "\n",
    "\n",
    "\n",
    "        # 2. Transition vs Physical\n",
    "        # --- Transition vs physical ---\n",
    "        tp_results = tp_pipe(chunks, top_k=None)\n",
    "    \n",
    "        for chunk_res in tp_results:\n",
    "            # chunk_res is list of dicts: [{'label': 'LABEL_0', 'score': 0.99}, ...]\n",
    "        \n",
    "            # Create a score lookup using the mapped names\n",
    "            scores = {label_map[d[\"label\"]]: d[\"score\"] for d in chunk_res}\n",
    "        \n",
    "            # Now you can safely extract\n",
    "            p_trans = scores.get(\"transition\", 0.0)\n",
    "            p_phys  = scores.get(\"physical\", 0.0)\n",
    "        \n",
    "            doc_scores[\"p_trans\"].append(p_trans)\n",
    "            doc_scores[\"p_phys\"].append(p_phys)\n",
    "        \n",
    "        # 3. Specificity\n",
    "        spec_results = spec_pipe(chunks)\n",
    "        for res in spec_results:\n",
    "            r = res if isinstance(res, dict) else res[0]\n",
    "            if r[\"label\"].lower() == \"high\":\n",
    "                doc_scores[\"p_spec_high\"].append(r[\"score\"])\n",
    "            else:\n",
    "                doc_scores[\"p_spec_high\"].append(1 - r[\"score\"])\n",
    "\n",
    "        # --- STEP 3: AGGREGATION (MAX POOLING) ---\n",
    "        # We take the MAXIMUM signal found in any chunk as the document signal.\n",
    "        # Use np.max with a default of 0.0 if the list is empty\n",
    "        \n",
    "        final_p_det = np.max(doc_scores[\"p_det\"]) if doc_scores[\"p_det\"] else 0.0\n",
    "        final_p_phys = np.max(doc_scores[\"p_phys\"]) if doc_scores[\"p_phys\"] else 0.0\n",
    "        final_p_trans = np.max(doc_scores[\"p_trans\"]) if doc_scores[\"p_trans\"] else 0.0\n",
    "        final_p_spec = np.max(doc_scores[\"p_spec_high\"]) if doc_scores[\"p_spec_high\"] else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            **meta,\n",
    "            \"item_1a_len\": len(item_1a), # Original length\n",
    "            \"chunks_processed\": len(chunks), # Useful metadata\n",
    "            \"p_det\": final_p_det,\n",
    "            \"p_phys\": final_p_phys,\n",
    "            \"p_trans\": final_p_trans,\n",
    "            \"p_spec_high\": final_p_spec,\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1978e218-5e0c-4b8f-a3e4-9c34f7d8ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          p_det    p_phys   p_trans  p_spec_high\n",
      "count  6.000000  6.000000  6.000000     6.000000\n",
      "mean   0.831035  0.783958  0.831944     0.747444\n",
      "std    0.404638  0.401360  0.407483     0.131271\n",
      "min    0.005074  0.000283  0.000190     0.548578\n",
      "25%    0.995172  0.779362  0.994707     0.661879\n",
      "50%    0.995859  0.998607  0.999564     0.802555\n",
      "75%    0.996269  0.999747  0.999612     0.840237\n",
      "max    0.998073  0.999841  0.999632     0.863191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>form</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>item_1a_len</th>\n",
       "      <th>p_det</th>\n",
       "      <th>p_phys</th>\n",
       "      <th>p_trans</th>\n",
       "      <th>p_spec_high</th>\n",
       "      <th>chunks_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1852536</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1121788</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021</td>\n",
       "      <td>93238</td>\n",
       "      <td>0.998073</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.618740</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66570</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>26524</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>0.706650</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>0.548578</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1866692</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>2024</td>\n",
       "      <td>161067</td>\n",
       "      <td>0.995573</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.993089</td>\n",
       "      <td>0.791294</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1766367</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1714899</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>2019</td>\n",
       "      <td>223699</td>\n",
       "      <td>0.995038</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.863191</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1711933</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>211703</td>\n",
       "      <td>0.996311</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.813816</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1566053</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1422222</td>\n",
       "      <td>10-K-A</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>11140</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.849044</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1580013</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cik    form filing_date  year  item_1a_len     p_det    p_phys  \\\n",
       "0  1852536    10-K  2024-05-02  2024            0       NaN       NaN   \n",
       "1  1121788    10-K  2021-02-17  2021        93238  0.998073  0.999841   \n",
       "2    66570    10-K  2016-02-29  2016        26524  0.996144  0.706650   \n",
       "3  1866692    10-K  2024-02-20  2024       161067  0.995573  0.999717   \n",
       "4  1766367    10-K  2020-03-18  2020            0       NaN       NaN   \n",
       "5  1714899    10-K  2019-03-12  2019       223699  0.995038  0.999757   \n",
       "6  1711933    10-K  2022-03-15  2022       211703  0.996311  0.997498   \n",
       "7  1566053    10-K  2019-03-25  2019            0       NaN       NaN   \n",
       "8  1422222  10-K-A  2018-01-04  2018        11140  0.005074  0.000283   \n",
       "9  1580013    10-K  2018-03-20  2018            0       NaN       NaN   \n",
       "\n",
       "    p_trans  p_spec_high  chunks_processed  \n",
       "0       NaN          NaN               NaN  \n",
       "1  0.999628     0.618740              46.0  \n",
       "2  0.999564     0.548578              13.0  \n",
       "3  0.993089     0.791294              79.0  \n",
       "4       NaN          NaN               NaN  \n",
       "5  0.999563     0.863191             108.0  \n",
       "6  0.999632     0.813816             100.0  \n",
       "7       NaN          NaN               NaN  \n",
       "8  0.000190     0.849044               6.0  \n",
       "9       NaN          NaN               NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(rows)\n",
    "\n",
    "print(df_test[[\"p_det\", \"p_phys\", \"p_trans\", \"p_spec_high\"]].describe())\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a382c01-9f42-44bb-895b-d6a77370e49b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1E. NLP Workflow building (ClimateBert: Climate Detector → Transition-Physical → Climate Specificit) - no keyword filtering - models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e07c38f3-eb04-4556-8f28-bbfacd995ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading Model: climatebert/distilroberta-base-climate-detector\n",
      "Loading Tokenizer: climatebert/distilroberta-base-climate-detector\n",
      "Loading Model: climatebert/transition-physical\n",
      "Loading Tokenizer: climatebert/distilroberta-base-climate-detector\n",
      "Loading Model: climatebert/distilroberta-base-climate-specificity\n",
      "Loading Tokenizer: climatebert/distilroberta-base-climate-specificity\n",
      "✅ All models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1) Setup Device & Load Models\n",
    "# --------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Helper to load model & tokenizer ---\n",
    "def load_climatebert_model(model_name, tokenizer_name=None):\n",
    "    \"\"\"\n",
    "    Loads model and tokenizer. \n",
    "    If tokenizer_name is NOT provided, it defaults to using model_name.\n",
    "    \"\"\"\n",
    "    if tokenizer_name is None:\n",
    "        tokenizer_name = model_name\n",
    "        \n",
    "    print(f\"Loading Model: {model_name}\")\n",
    "    print(f\"Loading Tokenizer: {tokenizer_name}\")\n",
    "    \n",
    "    # Load tokenizer from the specific source (which might differ from model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    # Load model weights\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "# A. Climate Detector\n",
    "# Both model and tokenizer exist in this repo\n",
    "det_name = \"climatebert/distilroberta-base-climate-detector\"\n",
    "det_tokenizer, det_model = load_climatebert_model(det_name)\n",
    "\n",
    "# B. Transition-Physical\n",
    "# ⚠️ THE FIX: We use the TP repo for the model, but the Detector repo for the tokenizer\n",
    "tp_model_name = \"climatebert/transition-physical\"\n",
    "tp_tokenizer_name = \"climatebert/distilroberta-base-climate-detector\" \n",
    "\n",
    "tp_tokenizer, tp_model = load_climatebert_model(\n",
    "    model_name=tp_model_name, \n",
    "    tokenizer_name=tp_tokenizer_name\n",
    ")\n",
    "\n",
    "# Label Map for Transition-Physical\n",
    "tp_label_map = {\n",
    "    0: \"transition\",\n",
    "    1: \"none\",\n",
    "    2: \"physical\"\n",
    "}\n",
    "\n",
    "# C. Climate Specificity\n",
    "spec_name = \"climatebert/distilroberta-base-climate-specificity\"\n",
    "spec_tokenizer, spec_model = load_climatebert_model(spec_name)\n",
    "\n",
    "print(\"✅ All models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8b2b5ec-87bc-4611-b99e-d58e2a9252eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2) Helper function for inference (the pipline was doing that before)\n",
    "# --------------------------\n",
    "\n",
    "def predict_batch(texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Runs inference on a list of texts (chunks) using the direct model.\n",
    "    Returns a list of dictionaries containing label probabilities.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize\n",
    "    # padding=True ensures all sequences in the batch have the same length\n",
    "    # truncation=True ensures we don't crash on >512 tokens\n",
    "    inputs = tokenizer(\n",
    "        texts, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # 2. Move inputs to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 3. Inference (No Gradient Calculation for speed)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 4. Convert Logits to Probabilities (Softmax)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # 5. Move back to CPU and convert to numpy/list\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------------\n",
    "# 3) Utility: parse filename\n",
    "# --------------------------\n",
    "\n",
    "def parse_filename_meta(path: Path):\n",
    "    fname = path.name\n",
    "    m = re.match(\n",
    "        r'(?P<date>\\d{8})_(?P<form>[0-9A-Z\\-]+)_edgar_data_(?P<cik>\\d+)_',\n",
    "        fname\n",
    "    )\n",
    "    if not m:\n",
    "        return {\"cik\": None, \"form\": None, \"filing_date\": None, \"year\": None}\n",
    "    date_str = m.group(\"date\")\n",
    "    filing_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "    return {\n",
    "        \"cik\": m.group(\"cik\"),\n",
    "        \"form\": m.group(\"form\"),\n",
    "        \"filing_date\": filing_date,\n",
    "        \"year\": int(date_str[:4]),\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# 4) Extract full Item 1A\n",
    "# --------------------------\n",
    "\n",
    "# def extract_item_1a(text: str):\n",
    "#     pattern = re.compile(\n",
    "#         r'ITEM\\s+1A\\.?(.*?)(ITEM\\s+1B\\.|ITEM\\s+2\\.)',\n",
    "#         flags=re.IGNORECASE | re.DOTALL\n",
    "#     )\n",
    "#     m = pattern.search(text)\n",
    "#     return m.group(1) if m else None\n",
    "\n",
    "def extract_item_1a(text: str):\n",
    "    \"\"\"\n",
    "    Robust extraction of Item 1A (Risk Factors).\n",
    "    Strategies used:\n",
    "    1. Case-insensitive search.\n",
    "    2. Mandatory 'Risk Factors' title to avoid TOC matches.\n",
    "    3. Finding ALL matches and returning the longest one (to bypass TOC entries).\n",
    "    \"\"\"\n",
    "    \n",
    "    # IMPROVEMENT 1: Look for \"Item 1A\" followed optionally by punctuation, \n",
    "    # then explicitly \"Risk Factors\". This filters out many TOC entries.\n",
    "    # We use [\\.\\:\\-\\s]* to allow for separators like \"Item 1A: Risk Factors\" or \"Item 1A. Risk Factors\"\n",
    "    # We use (?i) for case insensitivity inside the pattern.\n",
    "    start_pattern = r'ITEM\\s+1A[\\.\\:\\-\\s]*Risk\\s+Factors'\n",
    "    \n",
    "    # IMPROVEMENT 2: The end pattern looks for the next likely headers (1B or 2).\n",
    "    # We include word boundaries (\\b) to avoid matching \"Item 20\" as \"Item 2\".\n",
    "    end_pattern = r'(ITEM\\s+1B|ITEM\\s+2)\\b'\n",
    "    \n",
    "    # Combine into a single regex.\n",
    "    # Note: We use DOTALL (re.S) so the dot (.) matches newlines.\n",
    "    regex = re.compile(\n",
    "        f\"({start_pattern})(.*?)({end_pattern})\", \n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    \n",
    "    matches = regex.findall(text)\n",
    "    \n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    # IMPROVEMENT 3: The \"Longest Match\" Heuristic.\n",
    "    # A TOC entry is usually short (< 500 chars). The real section is long.\n",
    "    # matches is a list of tuples: [(start_match, content, end_match), ...]\n",
    "    # We want the 'content' group (index 1).\n",
    "    candidates = [m[1] for m in matches]\n",
    "    \n",
    "    # Sort by length, descending, and take the longest.\n",
    "    best_candidate = max(candidates, key=len)\n",
    "    \n",
    "    # Optional: Logic to reject if even the best candidate is too short to be real\n",
    "    if len(best_candidate) < 1000:\n",
    "        return None\n",
    "\n",
    "    return best_candidate.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15f2860d-235e-44e9-9836-d33dadf1d845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_TEST = 10  \n",
    "\n",
    "if len(all_files) <= N_TEST:\n",
    "    sample_files = all_files\n",
    "else:\n",
    "    sample_files = random.sample(all_files, N_TEST)\n",
    "\n",
    "len(sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95857cf3-cc2e-414f-91ff-2e4c0e6bdecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5635188009428bbb9f01bd23a8649c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing ClimateBERT (full 1A):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5) Process all files\n",
    "# --------------------------\n",
    "\n",
    "# Configuration for sliding window\n",
    "# 512 is the hard limit for BERT-based models. \n",
    "# We use slightly less (500) to leave room for special tokens [CLS], [SEP] added by the pipeline.\n",
    "CHUNK_SIZE = 500  \n",
    "STRIDE = 100       # Overlap between chunks to ensure context isn't lost at the edges\n",
    "\n",
    "def get_sliding_windows(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes text and slices it into overlapping windows.\n",
    "    Returns a list of decoded string chunks safe for the model.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize the entire document at once (no truncation yet)\n",
    "    encodings = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    input_ids = encodings[\"input_ids\"][0]\n",
    "    \n",
    "    # 2. If text is short, return it as a single chunk\n",
    "    if len(input_ids) <= CHUNK_SIZE:\n",
    "        return [text]\n",
    "    \n",
    "    # 3. Create windows\n",
    "    windows = []\n",
    "    total_tokens = len(input_ids)\n",
    "    \n",
    "    for i in range(0, total_tokens, CHUNK_SIZE - STRIDE):\n",
    "        # Define the window\n",
    "        chunk_ids = input_ids[i : i + CHUNK_SIZE]\n",
    "        \n",
    "        # Decode back to string so the pipeline can consume it naturally\n",
    "        # skip_special_tokens=True ensures we don't end up with weird [UNK] artifacts\n",
    "        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        windows.append(chunk_text)\n",
    "        \n",
    "        # Stop if we've reached the end\n",
    "        if i + CHUNK_SIZE >= total_tokens:\n",
    "            break\n",
    "            \n",
    "    return windows\n",
    "\n",
    "# --------------------------\n",
    "# 6) Process with Sliding Window\n",
    "# --------------------------\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Access the tokenizer from one of your pipes (assuming they share similar base arch like DistilRoBERTa)\n",
    "# If they are different architectures, use the specific tokenizer for each pipe.\n",
    "main_tokenizer = detector_pipe.tokenizer \n",
    "\n",
    "for path in tqdm(all_files, desc=\"Testing ClimateBERT (full 1A)\"):\n",
    "    meta = parse_filename_meta(path)\n",
    "    try:\n",
    "        text = path.read_text(errors=\"ignore\")\n",
    "        item_1a = extract_item_1a(text)\n",
    "        \n",
    "        # Skip empty files immediately\n",
    "        if not item_1a:\n",
    "            rows.append({**meta, \"item_1a_len\": 0, \"p_det\": None, \"p_phys\": None, \"p_trans\": None, \"p_spec_high\": None})\n",
    "            continue\n",
    "\n",
    "        # --- STEP 1: CHUNK THE TEXT ---\n",
    "        # Instead of item_1a[:4500], we get a list of valid token-safe strings\n",
    "        chunks = get_sliding_windows(item_1a, main_tokenizer)\n",
    "\n",
    "        # Storage for scores across all chunks in this document\n",
    "        doc_scores = {\n",
    "            \"p_det\": [],\n",
    "            \"p_phys\": [],\n",
    "            \"p_trans\": [],\n",
    "            \"p_spec_high\": []\n",
    "        }\n",
    "\n",
    "        # --- STEP 2: BATCH INFERENCE ---\n",
    "        # Passing the list 'chunks' directly to pipe() allows it to batch process if on GPU\n",
    "        # We process all chunks for the document at once.\n",
    "        \n",
    "        # 1. Detector\n",
    "        # Returns array of shape (n_chunks, 2) -> [prob_not_climate, prob_climate]\n",
    "        det_probs = predict_batch(chunks, det_tokenizer, det_model)\n",
    "        \n",
    "        # Assuming label 1 is \"yes\" (check model card if unsure, usually 1=climate)\n",
    "        # We take the probability of class 1 for every chunk\n",
    "        chunk_det_scores = det_probs[:, 1] \n",
    "        doc_scores[\"p_det\"].extend(chunk_det_scores.tolist())\n",
    "\n",
    "        # 2. Transition vs Physical\n",
    "        # Returns array of shape (n_chunks, 3) -> [prob_trans, prob_none, prob_phys]\n",
    "        tp_probs = predict_batch(chunks, tp_tokenizer, tp_model)\n",
    "        \n",
    "        # Extract columns based on your label map: 0=trans, 1=none, 2=phys\n",
    "        # We interpret the columns directly\n",
    "        chunk_trans_scores = tp_probs[:, 0]\n",
    "        chunk_phys_scores  = tp_probs[:, 2]\n",
    "        \n",
    "        doc_scores[\"p_trans\"].extend(chunk_trans_scores.tolist())\n",
    "        doc_scores[\"p_phys\"].extend(chunk_phys_scores.tolist())\n",
    "\n",
    "        # 3. Specificity\n",
    "        # Returns array of shape (n_chunks, 2) -> [prob_non_specific, prob_specific]\n",
    "        spec_probs = predict_batch(chunks, spec_tokenizer, spec_model)\n",
    "        \n",
    "        # Assuming label 1 is \"specific\" (high specificity)\n",
    "        chunk_spec_scores = spec_probs[:, 1]\n",
    "        doc_scores[\"p_spec_high\"].extend(chunk_spec_scores.tolist())\n",
    "\n",
    "        # --- STEP 3: AGGREGATION (MAX POOLING) ---\n",
    "        # We take the MAXIMUM signal found in any chunk as the document signal.\n",
    "        # Use np.max with a default of 0.0 if the list is empty\n",
    "        \n",
    "        final_p_det = np.max(doc_scores[\"p_det\"]) if doc_scores[\"p_det\"] else 0.0\n",
    "        final_p_phys = np.max(doc_scores[\"p_phys\"]) if doc_scores[\"p_phys\"] else 0.0\n",
    "        final_p_trans = np.max(doc_scores[\"p_trans\"]) if doc_scores[\"p_trans\"] else 0.0\n",
    "        final_p_spec = np.max(doc_scores[\"p_spec_high\"]) if doc_scores[\"p_spec_high\"] else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            **meta,\n",
    "            \"item_1a_len\": len(item_1a), # Original length\n",
    "            \"chunks_processed\": len(chunks), # Useful metadata\n",
    "            \"p_det\": final_p_det,\n",
    "            \"p_phys\": final_p_phys,\n",
    "            \"p_trans\": final_p_trans,\n",
    "            \"p_spec_high\": final_p_spec,\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39cee95e-742e-4783-95e7-6439a87d9abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistical Summary ---\n",
      "          p_det    p_phys   p_trans  p_spec_high\n",
      "count  8.000000  8.000000  8.000000     8.000000\n",
      "mean   0.506997  0.628909  0.282909     0.699845\n",
      "std    0.441254  0.511877  0.451222     0.125633\n",
      "min    0.005358  0.000089  0.000113     0.490366\n",
      "25%    0.032214  0.024349  0.000533     0.605845\n",
      "50%    0.568285  0.999633  0.001620     0.734516\n",
      "75%    0.904260  0.999771  0.444992     0.790204\n",
      "max    0.998411  0.999824  0.999645     0.853039\n",
      "\n",
      "--- Logic Checks ---\n",
      "Average chunks per file: 31.0 (Should be > 20 for 10-Ks)\n",
      "Max Physical Risk Score: 0.9998 (Should be > 0.9)\n",
      "Empty/Skipped Files: 2 (20.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>form</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>year</th>\n",
       "      <th>item_1a_len</th>\n",
       "      <th>chunks_processed</th>\n",
       "      <th>p_det</th>\n",
       "      <th>p_phys</th>\n",
       "      <th>p_trans</th>\n",
       "      <th>p_spec_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728535</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>2021</td>\n",
       "      <td>18564</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.581702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1423774</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020</td>\n",
       "      <td>154176</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.461224</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.756016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749273</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34903</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>2023</td>\n",
       "      <td>5121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.613892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1785705</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1719881</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>2019</td>\n",
       "      <td>69170</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.675346</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.260241</td>\n",
       "      <td>0.785043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1267332</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2016</td>\n",
       "      <td>10523</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.490366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1403802</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>44009</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.713016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1705843</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>2023</td>\n",
       "      <td>99755</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999244</td>\n",
       "      <td>0.853039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1373715</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2016-02-25</td>\n",
       "      <td>2016</td>\n",
       "      <td>97683</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.805686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cik  form filing_date  year  item_1a_len  chunks_processed     p_det  \\\n",
       "0   728535  10-K  2021-02-23  2021        18564               9.0  0.998411   \n",
       "1  1423774  10-K  2020-03-31  2020       154176              76.0  0.461224   \n",
       "2  1749273  10-K  2021-03-26  2021            0               NaN       NaN   \n",
       "3    34903  10-K  2023-02-08  2023         5121               3.0  0.005358   \n",
       "4  1785705  10-K  2021-03-30  2021            0               NaN       NaN   \n",
       "5  1719881  10-K  2019-09-09  2019        69170              36.0  0.675346   \n",
       "6  1267332  10-K  2016-03-22  2016        10523               6.0  0.006926   \n",
       "7  1403802  10-K  2016-03-30  2016        44009              21.0  0.040643   \n",
       "8  1705843  10-K  2023-03-02  2023        99755              48.0  0.993582   \n",
       "9  1373715  10-K  2016-02-25  2016        97683              49.0  0.874486   \n",
       "\n",
       "     p_phys   p_trans  p_spec_high  \n",
       "0  0.999764  0.999645     0.581702  \n",
       "1  0.999700  0.001047     0.756016  \n",
       "2       NaN       NaN          NaN  \n",
       "3  0.000089  0.000113     0.613892  \n",
       "4       NaN       NaN          NaN  \n",
       "5  0.999566  0.260241     0.785043  \n",
       "6  0.000111  0.000120     0.490366  \n",
       "7  0.032428  0.000671     0.713016  \n",
       "8  0.999824  0.999244     0.853039  \n",
       "9  0.999789  0.002194     0.805686  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame(rows)\n",
    "\n",
    "# 1. Basic Stats\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "print(df_final[[\"p_det\", \"p_phys\", \"p_trans\", \"p_spec_high\"]].describe())\n",
    "\n",
    "# 2. Senior Dev Logic Checks\n",
    "print(\"\\n--- Logic Checks ---\")\n",
    "\n",
    "# CHECK A: Did we actually process chunks?\n",
    "# If mean chunks_processed is ~1.0, your extraction logic failed (you are scanning titles, not text).\n",
    "avg_chunks = df_final[\"chunks_processed\"].mean()\n",
    "print(f\"Average chunks per file: {avg_chunks:.1f} (Should be > 20 for 10-Ks)\")\n",
    "\n",
    "# CHECK B: Do we have ANY Physical Risk detected?\n",
    "# If max(p_phys) is 0.0, your label mapping (LABEL_0/1/2) is likely wrong.\n",
    "max_phys = df_final[\"p_phys\"].max()\n",
    "print(f\"Max Physical Risk Score: {max_phys:.4f} (Should be > 0.9)\")\n",
    "\n",
    "# CHECK C: How many 'empty' files did we skip?\n",
    "# Count rows where item_1a_len is 0\n",
    "empty_count = len(df_final[df_final[\"item_1a_len\"] == 0])\n",
    "print(f\"Empty/Skipped Files: {empty_count} ({(empty_count/len(df_final))*100:.1f}%)\")\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95208267-b769-4fd0-aa71-a3564b081961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Backup saved to GCS: gs://tenk-bucket/climatebert/output/TEST_RESULTS.parquet\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"tenk-bucket\" \n",
    "GCS_PATH = f\"gs://{BUCKET_NAME}/climatebert/output/FINAL_RESULTS.parquet\"\n",
    "\n",
    "try:\n",
    "    df_final.to_parquet(GCS_PATH, index=False)\n",
    "    print(f\"✅ Backup saved to GCS: {GCS_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not save to GCS (check permissions/bucket name): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5ce28-fe3b-4c60-b2b8-e21f81951732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
